{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 Task 5\n",
    "Implemented from article: <br>\n",
    "https://levelup.gitconnected.com/building-stable-diffusion-from-scratch-using-python-f3ebc8c42da3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "%pip install einops\n",
    "\"\"\"\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "from einops import rearrange # For rearranging tensors\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gausian random features\n",
    "# Used for time-embedding. When score function is dependent on time,\n",
    "# Time is essentially many sinusoidal features. \n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    def __init__(self, embed_dim, scale = 30):\n",
    "        super().__init__()\n",
    "        # fixed during opt => no training\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim//2) * scale, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # project the tensor into sine and cosine components (concatenated for output)\n",
    "        # see article for more info\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat( [torch.sin(x_proj), torch.cos(x_proj)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC later: output -> feature map\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Slightly bewildering but simply casts 2D tensor -> 4D tensor\n",
    "        # This is to make it suitable as a feature map for later layers\n",
    "        return self.dense(x)[..., None, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBI\n",
    "def score_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler \n",
    "# Sampling: Random img -> guess noise -> remove said noise -> repeat\n",
    "# Can be done in several ways. Here with the Euler-Murayama method (same as article)\n",
    "def em_sampler(model, marginal_prob_std, diff_coef, \n",
    "               batch_size = BATCH_SIZE, num_steps = 500, y_tensor = None):\n",
    "    eps = 1e-3\n",
    "    x_shape = (1,28,28)\n",
    "\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    init_x = torch.randn(batch_size, *x_shape, device=device) * marginal_prob_std(t)[:,None,None,None]\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    x = init_x\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for time_step in tqdm(time_steps):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "            g = diff_coef(batch_time_step)\n",
    "            mean_x = x + (g**2)[:,None,None,None] * score_model(x, batch_time_step, y=y_tensor) * step_size\n",
    "            x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.rand_like(x)\n",
    "    \n",
    "    return mean_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main score model \n",
    "# We opt for a U-Net architecture as described in the article.\n",
    "# We use the res variant, where skip-connections add instead of concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# \n",
    "model = ...\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 1024\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
