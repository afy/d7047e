{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_ROOT = './data'\n",
    "NUM_CHANNELS = 3 # RGB format\n",
    "NUM_CLASSES_CIFAR10 = 10 # In CIFAR10 Dataset\n",
    "EPOCHS = 5 #70\n",
    "BATCH_SIZE = 50 # Required = 1, for now\n",
    "ALLOW_CUDA_TF32_CORES = True # Enable tensor cores on nvidia gpus (ampere gen. and above)\n",
    "ALLOW_CUDA = True # Overwrites all CUDA setup; enables standard CPU usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    transf_test = v2.Compose([\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.RandomVerticalFlip(),\n",
    "        v2.ToTensor()\n",
    "    ])\n",
    "    transf_train = v2.Compose([\n",
    "        v2.ToTensor()\n",
    "    ])\n",
    "\n",
    "    testset = CIFAR10(root=SET_ROOT, \n",
    "                    train=False, \n",
    "                    download=True, \n",
    "                    transform=transf_test)\n",
    "\n",
    "    trainset = CIFAR10(root=SET_ROOT, \n",
    "                    train=True, \n",
    "                    download=True, \n",
    "                    transform=transf_train)\n",
    "\n",
    "    print(f\"Len test: {len(testset)}, Len train: {len(trainset)}\")\n",
    "    train_size= int(0.8 * len(trainset))\n",
    "    val_size = len(trainset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda devices:  1\n",
      "0 , name: NVIDIA GeForce RTX 3070\n",
      "Enabling TF32 matmul\n"
     ]
    }
   ],
   "source": [
    "# CUDA setup\n",
    "\n",
    "if ALLOW_CUDA:\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    if not cuda_available:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(device)\n",
    "\n",
    "    else:\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(device, \"devices: \", torch.cuda.device_count())\n",
    "        print(torch.cuda.current_device(), \", name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "        # For my home GPU, for matrix multiplication speedup\n",
    "        # If you dont have a nvidia 30-series or above disable \n",
    "        # via the ALLOW_CUDA_TF32_CORES in the top of this file\n",
    "        # -Hannes\n",
    "        if ALLOW_CUDA_TF32_CORES:\n",
    "            print(\"Enabling TF32 matmul\")\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "        else:\n",
    "            # Revert to default\n",
    "            torch.backends.cuda.matmul.allow_tf32 = False\n",
    "            torch.backends.cudnn.allow_tf32 = False\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self, act_func=nn.LeakyReLU):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=NUM_CHANNELS, out_channels=10, kernel_size=2, device=device)\n",
    "        self.af1 = act_func()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=2, device=device)\n",
    "        self.af2 = act_func()\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # In-features is now hardcoded\n",
    "        # Figure out how to calculate dynamically\n",
    "        self.fc1 = nn.Linear(in_features=4500, out_features=NUM_CLASSES_CIFAR10, device=device)\n",
    "        self.lsfm1 = nn.LogSoftmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.af1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.af2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.lsfm1(x)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, criterion, optimizer, train_loader):\n",
    "        for epoch in range(EPOCHS):\n",
    "            self.train() # training mode       \n",
    "            for batch_i, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.float().to(device), labels.to(device) \n",
    "                loss = criterion(self(images), labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                print(epoch, loss.item(), batch_i+1)\n",
    "\n",
    "\n",
    "    def test_model(self, test_loader):\n",
    "        with torch.no_grad():\n",
    "            self.eval() # evaluation mode\n",
    "            correct, total = 0,0 \n",
    "            for batch_i, (images, labels) in enumerate(test_loader):\n",
    "                images, labels = images.float().to(device), labels.to(device)\n",
    "                pred = torch.argmax(self(images), dim=1)\n",
    "                correct += (pred == labels).sum()\n",
    "                total += len(pred)\n",
    "\n",
    "            print(f\"Correct: {correct}, Total: {total}, Acc: {correct/total*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanne\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Len test: 10000, Len train: 50000\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "0 2.300020456314087 800\n",
      "1 2.3024566173553467 800\n",
      "2 2.298409938812256 800\n",
      "3 2.2984113693237305 800\n",
      "4 2.2978098392486572 800\n",
      "Correct: 1700, Total: 10000, Acc: 17.0%\n"
     ]
    }
   ],
   "source": [
    "# Default: LeakyReLU, SGD\n",
    "model = CNN1()\n",
    "if torch.cuda.is_available() and ALLOW_CUDA: \n",
    "    print(\"Using cuda\")\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.train_model(criterion, optimizer, train_loader)\n",
    "model.test_model(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeakyReLU, Adam\n",
    "model2 = CNN1()\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.0001)\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "model2.train_model(criterion2, optimizer2)\n",
    "model2.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanh, SGD\n",
    "model3 = CNN1(act_func=nn.Tanh)\n",
    "optimizer3 = torch.optim.SGD(model3.parameters(), lr=0.0001)\n",
    "criterion3 = nn.CrossEntropyLoss()\n",
    "model3.train_model(criterion3, optimizer3)\n",
    "model3.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
