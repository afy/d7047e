{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T14:44:03.293823Z",
     "start_time": "2024-04-29T14:44:03.287395Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24491399490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")\n",
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f58a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST('./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2fb8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From paper\n",
    "def Std_loss_func(D_real, D_fake, discriminator = True):\n",
    "     if (discriminator):\n",
    "          return -torch.mean(torch.log(D_real) + torch.log(torch.ones(D_fake.shape) - D_fake))\n",
    "     \n",
    "     return -torch.mean(torch.log(D_fake))\n",
    "\n",
    "# task 2\n",
    "def Logis_loss():\n",
    "     pass\n",
    "\n",
    "# Random sample\n",
    "def sample_Z(m, n):\n",
    "    return torch.randn(m, n)\n",
    "\n",
    "# Re-implement \n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / (in_dim / 2.)**0.5  # Using standard Python sqrt calculation\n",
    "    return torch.randn(*size) * xavier_stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "267748fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.W1 = nn.Parameter(xavier_init([784, 128]))\n",
    "        self.b1 = nn.Parameter(torch.zeros(128))\n",
    "        self.W2 = nn.Parameter(xavier_init([128, 1]))\n",
    "        self.b2 = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(x @ self.W1 + self.b1)\n",
    "        logits = x @ self.W2 + self.b2\n",
    "        prob = torch.sigmoid(logits)\n",
    "        return prob, logits\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, zdim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.W1 = nn.Parameter(xavier_init([zdim, 128]))\n",
    "        self.b1 = nn.Parameter(torch.zeros(128))\n",
    "        self.W2 = nn.Parameter(xavier_init([128, 784]))\n",
    "        self.b2 = nn.Parameter(torch.zeros(784))\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = torch.relu(z @ self.W1 + self.b1)\n",
    "        log_prob = z @ self.W2 + self.b2\n",
    "        prob = torch.sigmoid(log_prob)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bd5118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: D_loss 1.5403958559036255, G_loss -0.0\n",
      "Iteration 100: D_loss 1.2407058477401733, G_loss -0.0\n",
      "Iteration 200: D_loss 1.1147315502166748, G_loss -0.0\n",
      "Iteration 300: D_loss 1.6881186962127686, G_loss -0.0\n",
      "Iteration 400: D_loss 1.4530378580093384, G_loss -0.0\n",
      "Iteration 500: D_loss 1.26717209815979, G_loss -0.0\n",
      "Iteration 600: D_loss 1.0657451152801514, G_loss -0.0\n",
      "Iteration 700: D_loss 1.1030070781707764, G_loss -0.0\n",
      "Iteration 800: D_loss 1.5058815479278564, G_loss -0.0\n",
      "Iteration 900: D_loss 1.5961940288543701, G_loss -0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m discriminator, generator\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# testing\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m D, G \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(loss_criterion)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20_000\u001b[39m):\n\u001b[0;32m     14\u001b[0m     \n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Update discriminator (k times)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m jt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k):  \n\u001b[1;32m---> 17\u001b[0m         (batch_images, batch_label)  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[0;32m     18\u001b[0m         batch_images \u001b[38;5;241m=\u001b[39m batch_images\u001b[38;5;241m.\u001b[39mview(batch_images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the image tensor if needed\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         Z \u001b[38;5;241m=\u001b[39m sample_Z(\u001b[38;5;241m1\u001b[39m, zdim)  \u001b[38;5;66;03m# Sample noise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = 1\n",
    "k = 1\n",
    "zdim = 100\n",
    "\n",
    "def train(loss_criterion=Std_loss_func):\n",
    "    generator = Generator(zdim=zdim)\n",
    "    discriminator = Discriminator()\n",
    "    D_optimizer = torch.optim.Adam(params=discriminator.parameters(), lr=0.001)\n",
    "    G_optimizer = torch.optim.Adam(params=generator.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=m, shuffle=True)\n",
    "\n",
    "    for it in range(20_000):\n",
    "        \n",
    "        # Update discriminator (k times)\n",
    "        for jt in range(k):  \n",
    "            (batch_images, batch_label)  = next(iter(train_loader))\n",
    "            batch_images = batch_images.view(batch_images.size(0), -1)  # Flatten the image tensor if needed\n",
    "            Z = sample_Z(1, zdim)  # Sample noise\n",
    "\n",
    "            D_optimizer.zero_grad()\n",
    "            x = generator(Z)\n",
    "\n",
    "            D_real, D_logit_real = discriminator(batch_images)\n",
    "            D_fake, D_logit_fake = discriminator(x)    \n",
    "\n",
    "            # print(D_real.shape, D_fake.shape, D_logit_real.shape, D_logit_fake.shape)\n",
    "\n",
    "            D_loss = loss_criterion(D_real, D_fake)\n",
    "            D_optimizer.step()\n",
    "\n",
    "        # Update generator\n",
    "        Z = sample_Z(1, zdim)  # Sample noise\n",
    "        G_optimizer.zero_grad()\n",
    "        G_fake, G_logit_fake = discriminator(generator(Z))\n",
    "        G_loss = loss_criterion(G_fake, torch.ones_like(G_fake), discriminator=False)\n",
    "        G_optimizer.step()\n",
    "\n",
    "        if it % 100 == 0:\n",
    "            print(f\"Iteration {it}: D_loss {D_loss}, G_loss {G_loss}\")\n",
    "\n",
    "    return discriminator, generator\n",
    "\n",
    "\n",
    "# testing\n",
    "D, G = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97389b7897e9e2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T15:22:57.113005Z",
     "start_time": "2024-04-29T15:22:51.910582Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with std loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with logistic loss\n",
    "D, G = train(Logis_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
