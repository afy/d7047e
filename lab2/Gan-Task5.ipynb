{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 Task 5\n",
    "Implemented from article: <br>\n",
    "https://levelup.gitconnected.com/building-stable-diffusion-from-scratch-using-python-f3ebc8c42da3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "%pip install einops\n",
    "\"\"\"\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# misc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "import functools\n",
    "import math\n",
    "import numpy as np\n",
    "from einops import rearrange # For rearranging tensors\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_cond(model, x, y, marginal_prob_std, eps=1e-5):\n",
    "    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps\n",
    "    z = torch.randn_like(x)\n",
    "    std = marginal_prob_std(random_t)\n",
    "    perturbed_x = x + z * std[:, None, None, None]\n",
    "    score = model(perturbed_x, random_t, y=y)\n",
    "    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1, 2, 3)))\n",
    "    return loss\n",
    "\n",
    "def dc(t, sigma):\n",
    "    return torch.tensor(sigma**t, device=device)\n",
    "\n",
    "def mps(t, sigma):\n",
    "    t = torch.tensor(t, device=device)\n",
    "    return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "sigma = 25.0\n",
    "marginal_prob_std = functools.partial(mps, sigma=sigma)\n",
    "diffusion_coeff = functools.partial(dc, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gausian random features\n",
    "# Used for time-embedding. When score function is dependent on time,\n",
    "# Time is essentially many sinusoidal features. \n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    def __init__(self, embed_dim, scale = 30.):\n",
    "        super().__init__()\n",
    "        # fixed during opt => no training\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim//2) * scale, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # project the tensor into sine and cosine components (concatenated for output)\n",
    "        # see article for more info\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat( [torch.sin(x_proj), torch.cos(x_proj)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC later: output -> feature map\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Slightly bewildering but simply casts 2D tensor -> 4D tensor\n",
    "        # This is to make it suitable as a feature map for later layers\n",
    "        return self.dense(x)[..., None, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler \n",
    "# Sampling: Random img -> guess noise -> remove said noise -> repeat\n",
    "# Can be done in several ways. Here with the Euler-Murayama method (same as article)\n",
    "def em_sampler(score_model, marginal_prob_std, diff_coef, \n",
    "               batch_size = 64, num_steps = 500, y_tensor = None):\n",
    "    eps = 1e-3\n",
    "    x_shape = (1,28,28)\n",
    "\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    init_x = torch.randn(batch_size, *x_shape, device=device) * marginal_prob_std(t)[:,None,None,None]\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    x = init_x\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for time_step in tqdm(time_steps):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "            g = diff_coef(batch_time_step)\n",
    "            mean_x = x + (g**2)[:,None,None,None] * score_model(x, batch_time_step, y=y_tensor) * step_size\n",
    "            x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.rand_like(x)\n",
    "    \n",
    "    return mean_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, context_dim=None, num_heads=1):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.context_dim = context_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.query = nn.Linear(hidden_dim, embed_dim, bias=False)\n",
    "        if context_dim is None:\n",
    "            self.self_attn = True\n",
    "            self.key = nn.Linear(hidden_dim, embed_dim, bias=False)\n",
    "            self.value = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        else:\n",
    "            self.self_attn = False\n",
    "            self.key = nn.Linear(context_dim, embed_dim, bias=False)\n",
    "            self.value = nn.Linear(context_dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, tokens, context=None):\n",
    "        if self.self_attn:\n",
    "            Q = self.query(tokens)\n",
    "            K = self.key(tokens)\n",
    "            V = self.value(tokens)\n",
    "        else:\n",
    "            Q = self.query(tokens)\n",
    "            K = self.key(context)\n",
    "            V = self.value(context)\n",
    "        scoremats = torch.einsum(\"BTH,BSH->BTS\", Q, K) \n",
    "        attnmats = F.softmax(scoremats / math.sqrt(self.embed_dim), dim=-1)  \n",
    "        ctx_vecs = torch.einsum(\"BTS,BSH->BTH\", attnmats, V)  \n",
    "        return ctx_vecs\n",
    "    \n",
    "\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, context_dim):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn_self = CrossAttention(hidden_dim, hidden_dim)\n",
    "        self.attn_cross = CrossAttention(hidden_dim, hidden_dim, context_dim)\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 3 * hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(3 * hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        x = self.attn_self(self.norm1(x)) + x\n",
    "        x = self.attn_cross(self.norm2(x), context=context) + x\n",
    "        x = self.ffn(self.norm3(x)) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class SpatialTransformer(nn.Module):\n",
    "    def __init__(self, hidden_dim, context_dim):\n",
    "        super(SpatialTransformer, self).__init__()\n",
    "        self.transformer = TransformerBlock(hidden_dim, context_dim)\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        b, c, h, w = x.shape\n",
    "        x_in = x\n",
    "        x = rearrange(x, \"b c h w -> b (h w) c\")\n",
    "        x = self.transformer(x, context)\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "        return x + x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_Tranformer(nn.Module):\n",
    "    def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256,\n",
    "                 text_dim=256, nClass=10):\n",
    "        super().__init__()\n",
    "        self.time_embed = nn.Sequential(\n",
    "            GaussianFourierProjection(embed_dim=embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
    "        self.dense1 = Dense(embed_dim, channels[0])\n",
    "        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "\n",
    "        self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
    "        self.dense2 = Dense(embed_dim, channels[1])\n",
    "        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "\n",
    "        self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
    "        self.dense3 = Dense(embed_dim, channels[2])\n",
    "        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        self.attn3 = SpatialTransformer(channels[2], text_dim)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
    "        self.dense4 = Dense(embed_dim, channels[3])\n",
    "        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "        self.attn4 = SpatialTransformer(channels[3], text_dim)\n",
    "\n",
    "        self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
    "        self.dense5 = Dense(embed_dim, channels[2])\n",
    "        self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "\n",
    "        self.tconv3 = nn.ConvTranspose2d(channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)\n",
    "        self.dense6 = Dense(embed_dim, channels[1])\n",
    "        self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "\n",
    "        self.tconv2 = nn.ConvTranspose2d(channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)\n",
    "        self.dense7 = Dense(embed_dim, channels[0])\n",
    "        self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "        self.tconv1 = nn.ConvTranspose2d(channels[0], 1, 3, stride=1)\n",
    "\n",
    "        self.act = nn.SiLU()\n",
    "        self.marginal_prob_std = marginal_prob_std\n",
    "        self.cond_embed = nn.Embedding(nClass, text_dim)\n",
    "\n",
    "    def forward(self, x, t, y=None):\n",
    "        embed = self.act(self.time_embed(t))\n",
    "        y_embed = self.cond_embed(y).unsqueeze(1)\n",
    "        h1 = self.conv1(x) + self.dense1(embed)\n",
    "        h1 = self.act(self.gnorm1(h1))\n",
    "        h2 = self.conv2(h1) + self.dense2(embed)\n",
    "        h2 = self.act(self.gnorm2(h2))\n",
    "        h3 = self.conv3(h2) + self.dense3(embed)\n",
    "        h3 = self.act(self.gnorm3(h3))\n",
    "        h3 = self.attn3(h3, y_embed)\n",
    "        h4 = self.conv4(h3) + self.dense4(embed)\n",
    "        h4 = self.act(self.gnorm4(h4))\n",
    "        h4 = self.attn4(h4, y_embed)\n",
    "        h = self.tconv4(h4) + self.dense5(embed)\n",
    "        h = self.act(self.tgnorm4(h))\n",
    "        h = self.tconv3(h + h3) + self.dense6(embed)\n",
    "        h = self.act(self.tgnorm3(h))\n",
    "        h = self.tconv2(h + h2) + self.dense7(embed)\n",
    "        h = self.act(self.tgnorm2(h))\n",
    "        h = self.tconv1(h + h1)\n",
    "        h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new model\n"
     ]
    }
   ],
   "source": [
    "continue_training = False\n",
    "if not continue_training:\n",
    "    print(\"Creating new model\")\n",
    "    score_model = torch.nn.DataParallel(UNet_Tranformer(marginal_prob_std=marginal_prob_std))\n",
    "    score_model = score_model.to(device)\n",
    "else:\n",
    "    print(\"Continuing on existing model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 2048\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = torchvision.datasets.MNIST('./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "optimizer = torch.optim.Adam(score_model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: max(0.2, 0.98 ** epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\hanne\\AppData\\Local\\Temp\\ipykernel_17084\\4052331727.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n",
      "Average Loss: 1331.211512:   4%|▍         | 1/25 [00:06<02:44,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Average Loss: 1331.211512 lr 9.8e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss: 82.803654:  44%|████▍     | 11/25 [01:15<01:36,  6.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Average Loss: 82.803654 lr 8.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss: 49.581664:  84%|████████▍ | 21/25 [02:24<00:27,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Average Loss: 49.581664 lr 6.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss: 44.432600: 100%|██████████| 25/25 [02:52<00:00,  6.89s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tqdm_epoch = trange(n_epochs)\n",
    "for epoch in tqdm_epoch:\n",
    "    avg_loss = 0.\n",
    "    num_items = 0\n",
    "\n",
    "    for x, y in data_loader:\n",
    "        x = x.to(device)\n",
    "        loss = loss_fn_cond(score_model, x, y, marginal_prob_std)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() * x.shape[0]\n",
    "        num_items += x.shape[0]\n",
    "\n",
    "    scheduler.step()\n",
    "    lr_current = scheduler.get_last_lr()[0]\n",
    "    if epoch % 10 == 0: print('{} Average Loss: {:5f} lr {:.1e}'.format(epoch, avg_loss / num_items, lr_current))\n",
    "    tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
    "    torch.save(score_model.state_dict(), 'ckpt_unet_sdiff.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if continue_training:\n",
    "    score_model = torch.nn.DataParallel(UNet_Tranformer(marginal_prob_std=marginal_prob_std))\n",
    "    score_model = score_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ckpt = torch.load('ckpt_unet_sdiff.pth', map_location=device)\n",
    "score_model.load_state_dict(ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanne\\AppData\\Local\\Temp\\ipykernel_17084\\4052331727.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\hanne\\AppData\\Local\\Temp\\ipykernel_17084\\4052331727.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(sigma**t, device=device)\n",
      "100%|██████████| 10/10 [00:00<00:00, 163.84it/s]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.4744e+00,  5.5297e+00,  3.8028e+00,  5.8367e+00,  3.8783e+00,\n",
      "           4.2829e+00,  3.8585e+00,  3.9665e+00,  3.0984e+00,  4.1602e+00,\n",
      "           3.6186e+00,  4.9360e+00,  3.6159e+00,  4.6362e+00,  3.2072e+00,\n",
      "           3.7900e+00,  2.6703e+00,  3.5237e+00,  2.5683e+00,  3.3276e+00,\n",
      "           2.6606e+00,  3.3589e+00,  4.1300e+00,  3.4265e+00,  3.9043e+00,\n",
      "           4.7612e+00,  8.9471e+00,  2.6943e+01],\n",
      "         [ 5.8626e-01,  3.0588e+00, -3.0872e-01,  1.8183e+00,  2.1107e+00,\n",
      "           2.4358e+00,  1.0850e+00,  1.5736e+00, -5.4026e-01,  1.2023e+00,\n",
      "           1.4840e+00,  1.8891e+00,  1.0624e+00,  1.0247e+00, -1.0841e+00,\n",
      "           5.1974e-01, -9.5643e-02,  3.8210e-01,  6.4002e-02, -4.7878e-01,\n",
      "           2.2953e-01,  4.7948e-01,  8.0800e-04,  9.1583e-01,  1.2045e-01,\n",
      "           6.9675e-01, -5.3104e-01,  1.9715e+00],\n",
      "         [ 2.8155e+00,  2.0202e+00, -6.6803e-01,  2.6793e+00,  2.2341e+00,\n",
      "           3.3519e+00,  4.0631e+00,  2.8172e+00,  2.1043e+00,  1.7119e+00,\n",
      "           1.0417e+00,  3.8943e+00,  4.5601e+00,  3.2796e+00,  1.4494e+00,\n",
      "           7.6207e-01,  6.6478e-02, -4.2110e-02, -1.0339e+00, -1.6293e+00,\n",
      "          -3.6372e-01, -4.6814e-01, -2.1121e+00,  1.2089e-01,  4.6240e+00,\n",
      "          -1.3579e+00, -1.9969e+00,  5.0929e+00],\n",
      "         [-5.6159e-01,  8.2537e-02,  4.6059e-01, -1.2432e+00,  1.1671e+00,\n",
      "           8.1737e-01,  3.4473e+00,  2.5405e+00,  3.1405e+00,  1.1781e+00,\n",
      "           2.0976e+00,  4.1005e+00,  4.7970e+00,  3.8514e+00,  2.0823e+00,\n",
      "          -5.5708e-01,  1.0390e+00, -8.9463e-01,  8.9614e-01, -2.6214e+00,\n",
      "           9.0331e-01, -2.4213e+00, -5.2621e-01, -1.4222e+00,  3.6539e+00,\n",
      "           3.1680e+00, -2.9133e+00,  2.4568e-01],\n",
      "         [ 2.0243e+00, -1.2492e-01,  5.1088e-01,  6.7498e-01,  2.3383e+00,\n",
      "           1.6641e+00,  3.6239e+00,  1.8115e+00,  2.5209e+00,  1.4684e+00,\n",
      "           3.6177e+00,  3.6707e+00,  5.2448e+00,  2.9827e+00,  1.9918e+00,\n",
      "           2.8003e-01,  2.2043e+00,  4.4885e-01,  1.8056e+00, -2.5043e+00,\n",
      "           1.6826e+00, -8.7919e-01,  1.0680e+00, -1.4173e-01,  4.4734e+00,\n",
      "          -1.9108e-01, -2.0582e+00, -1.0972e+00],\n",
      "         [ 8.5466e-02,  1.9597e+00,  9.2376e-01, -1.9010e+00, -4.5081e-01,\n",
      "          -8.5053e-01,  1.5863e+00, -1.2982e+00,  8.5988e-01,  8.5564e-01,\n",
      "           3.6505e+00,  1.7334e+00,  2.5390e+00,  2.5635e+00,  2.5436e+00,\n",
      "           7.1576e-01,  1.4116e+00,  1.0662e+00,  2.0071e+00, -2.3432e-01,\n",
      "           2.1347e+00, -1.8190e-01,  6.4293e-01, -2.5291e+00,  1.2954e-01,\n",
      "           2.5357e+00, -3.4231e+00, -5.4591e-01],\n",
      "         [ 1.7203e+00,  1.3396e-01, -4.5682e-01, -1.4273e+00,  9.1565e-01,\n",
      "          -5.9905e-01,  5.9399e-01, -9.0670e-01,  1.3993e+00,  1.0875e+00,\n",
      "           1.9334e+00,  3.0885e+00,  5.6665e+00,  3.9956e+00,  4.5632e+00,\n",
      "           4.4984e+00,  6.6460e+00,  3.1131e+00,  4.6684e+00,  8.2020e-01,\n",
      "           2.8988e+00,  9.5985e-01,  7.0838e-01, -2.1849e+00,  2.9624e+00,\n",
      "           3.5282e-01, -1.3812e+00, -2.0804e+00],\n",
      "         [-2.9723e-01,  1.5941e+00,  1.3500e+00, -1.8244e+00, -3.9166e-01,\n",
      "          -2.2175e+00,  4.8412e-01, -3.0129e+00,  9.7896e-01, -7.2272e-02,\n",
      "           2.6922e+00,  2.7542e+00,  6.2983e+00,  5.5959e+00,  6.7211e+00,\n",
      "           7.7492e+00,  7.4215e+00,  6.2385e+00,  5.3276e+00,  2.5949e+00,\n",
      "           3.1686e+00,  2.5191e+00,  1.4695e+00, -1.1712e+00, -5.2421e-01,\n",
      "           1.4224e+00, -3.0313e+00, -8.2724e-01],\n",
      "         [ 1.6031e+00,  4.6479e-01,  5.0815e-01, -9.0284e-01,  7.8659e-01,\n",
      "          -8.9975e-01,  1.8975e-01, -1.0333e+00,  1.7425e+00,  9.5556e-01,\n",
      "           3.2157e+00,  4.2643e+00,  8.6585e+00,  4.7371e+00,  6.5497e+00,\n",
      "           6.7108e+00,  1.0229e+01,  5.0285e+00,  7.4129e+00,  3.4613e+00,\n",
      "           6.5404e+00,  3.1513e+00,  3.0232e+00, -1.1951e+00,  2.0206e+00,\n",
      "          -4.8126e-01, -6.8707e-01, -1.8210e+00],\n",
      "         [ 4.9878e-01,  1.9952e+00,  9.3386e-01, -6.5258e-01, -4.3045e-02,\n",
      "          -1.6286e+00,  2.5064e-01, -2.1469e+00,  2.4749e+00,  1.0338e+00,\n",
      "           5.3032e+00,  5.6970e+00,  8.6090e+00,  5.2046e+00,  7.7604e+00,\n",
      "           8.2946e+00,  9.1524e+00,  8.1473e+00,  8.5973e+00,  5.9493e+00,\n",
      "           5.6348e+00,  5.5374e+00,  2.5584e+00, -2.8489e-01,  3.6110e-01,\n",
      "           2.1649e+00, -2.6590e+00, -4.5205e-01],\n",
      "         [ 1.8138e+00,  1.1121e+00,  6.5348e-01, -3.7389e-01,  6.4738e-01,\n",
      "          -6.4592e-01,  4.2838e-01,  3.3144e-02,  1.4687e+00,  3.5349e+00,\n",
      "           7.1014e+00,  5.2694e+00,  7.9479e+00,  3.1217e+00,  8.0682e+00,\n",
      "           6.0578e+00,  1.1477e+01,  4.2857e+00,  1.0850e+01,  7.1662e+00,\n",
      "           9.5915e+00,  4.0258e+00,  2.3764e+00,  1.5498e+00,  3.8642e+00,\n",
      "           4.7707e-01, -7.0152e-01, -2.1760e+00],\n",
      "         [ 3.3253e-01,  2.5402e+00,  1.9368e+00, -4.1211e-01,  8.5902e-01,\n",
      "          -7.6723e-01,  9.8201e-01, -1.2304e+00,  2.1253e+00,  3.9830e+00,\n",
      "           7.1150e+00,  6.2497e+00,  8.8144e+00,  5.6299e+00,  7.3844e+00,\n",
      "           7.4996e+00,  8.4093e+00,  5.0649e+00,  7.3107e+00,  9.5448e+00,\n",
      "           8.0168e+00,  3.6884e+00,  2.0529e+00,  9.7626e-01,  1.3445e+00,\n",
      "           3.4296e+00, -2.8719e+00, -8.1176e-01],\n",
      "         [ 2.2526e+00,  1.0621e+00, -8.6457e-02,  3.2032e-01,  1.5976e+00,\n",
      "           1.9035e-01,  2.5915e+00,  8.4667e-01,  4.7582e+00,  3.7749e+00,\n",
      "           8.5697e+00,  5.1800e+00,  8.3224e+00,  2.6984e+00,  9.6915e+00,\n",
      "           6.9527e+00,  1.1356e+01,  1.1877e+00,  1.1822e+01,  7.6423e+00,\n",
      "           1.0065e+01,  1.5266e+00,  1.6789e+00,  1.3371e+00,  3.3649e+00,\n",
      "           6.8836e-01, -1.6221e+00, -2.0467e+00],\n",
      "         [ 2.9954e-01,  2.2778e+00,  1.4817e+00, -6.1938e-01,  1.6797e+00,\n",
      "           1.0250e+00,  3.6396e+00,  2.7068e+00,  5.7596e+00,  4.4157e+00,\n",
      "           7.2513e+00,  5.8081e+00,  7.4003e+00,  6.6586e+00,  9.8452e+00,\n",
      "           8.7125e+00,  8.1442e+00,  5.8390e+00,  8.8819e+00,  9.2060e+00,\n",
      "           6.6840e+00,  1.7455e-03,  9.0341e-01, -1.9419e+00,  9.6438e-02,\n",
      "           2.2030e+00, -3.5475e+00, -4.1635e-01],\n",
      "         [ 1.3954e+00,  6.9883e-01,  2.9475e-02, -1.7245e+00,  1.3479e+00,\n",
      "           6.1919e-01,  2.9630e+00,  2.0824e+00,  6.5775e+00,  5.0442e+00,\n",
      "           8.3559e+00,  5.4052e+00,  8.6715e+00,  3.5166e+00,  1.1733e+01,\n",
      "           4.7528e+00,  1.3233e+01,  4.7108e+00,  1.1620e+01,  4.2231e+00,\n",
      "           5.8700e+00,  6.9830e-01, -1.9348e+00, -1.8036e+00,  2.6308e+00,\n",
      "          -2.3451e-01, -1.3560e+00, -2.1709e+00],\n",
      "         [ 3.7171e-01,  1.4624e+00,  1.8652e+00, -1.6622e+00,  5.6503e-01,\n",
      "          -7.6740e-01,  2.4999e+00,  3.3930e+00,  7.9011e+00,  7.3844e+00,\n",
      "           9.7915e+00,  7.7411e+00,  1.0086e+01,  8.1726e+00,  1.0642e+01,\n",
      "           8.3815e+00,  9.9852e+00,  8.0021e+00,  6.4600e+00,  2.5124e+00,\n",
      "           4.6170e+00,  1.0588e+00, -9.5578e-02, -2.4972e+00, -1.5916e-01,\n",
      "           1.5279e+00, -2.5790e+00, -1.0945e-01],\n",
      "         [ 2.3351e+00,  4.6269e-01,  4.2166e-01, -1.2132e+00,  1.0510e+00,\n",
      "          -1.1297e+00,  1.1381e+00,  1.7059e+00,  6.2918e+00,  4.1181e+00,\n",
      "           6.6678e+00,  5.5959e+00,  9.0574e+00,  5.1899e+00,  1.0418e+01,\n",
      "           5.8419e+00,  1.4054e+01,  5.6121e+00,  8.3135e+00,  3.4331e+00,\n",
      "           6.0881e+00,  6.2396e-01,  2.0156e-01, -1.2933e+00,  2.7335e+00,\n",
      "          -7.0937e-01, -6.5279e-01, -2.4241e+00],\n",
      "         [ 2.2018e-01,  1.8608e+00,  4.2627e-01, -2.7315e+00, -1.5650e+00,\n",
      "          -2.8099e+00, -4.3848e-01, -1.4377e-01,  4.1177e+00,  2.2327e+00,\n",
      "           4.7761e+00,  4.4656e+00,  7.6846e+00,  6.1051e+00,  8.1956e+00,\n",
      "           8.4122e+00,  8.6744e+00,  7.9773e+00,  7.8325e+00,  2.5666e+00,\n",
      "           4.3363e+00,  1.1520e+00,  6.9891e-01, -1.8058e+00,  3.5241e-01,\n",
      "           1.5039e+00, -3.2175e+00,  6.8088e-02],\n",
      "         [ 1.7824e+00,  1.0344e+00, -5.8455e-01, -3.0584e+00,  1.6815e-02,\n",
      "          -8.8016e-01,  4.8202e-01,  1.3494e+00,  3.8154e+00,  3.1023e+00,\n",
      "           4.0032e+00,  3.6838e+00,  6.6409e+00,  5.1301e+00,  1.1629e+01,\n",
      "           7.1536e+00,  1.2045e+01,  3.8167e+00,  7.7224e+00,  3.6293e+00,\n",
      "           3.8732e+00,  1.6115e+00, -3.8871e-02, -2.1543e+00,  3.1421e+00,\n",
      "          -5.9353e-01, -7.6470e-01, -2.4749e+00],\n",
      "         [ 6.0336e-01,  1.2443e+00,  8.7496e-01, -2.7277e+00, -3.4887e-01,\n",
      "          -3.1350e+00, -1.3317e+00, -1.2417e+00,  3.4728e+00,  3.6166e+00,\n",
      "           2.8611e+00,  1.7046e+00,  5.1466e+00,  7.5517e+00,  1.0909e+01,\n",
      "           8.4229e+00,  5.7839e+00,  2.1943e+00,  5.8738e+00,  3.1403e+00,\n",
      "           4.3286e+00,  7.4785e-01,  3.5767e-02, -2.3828e+00,  7.0564e-01,\n",
      "           1.4096e+00, -2.8706e+00, -3.7688e-01],\n",
      "         [ 2.0717e+00,  7.2441e-01,  3.2305e-01, -2.5492e+00, -1.8522e-01,\n",
      "          -1.4098e+00,  2.1158e+00,  3.1374e+00,  8.7968e+00,  3.9269e+00,\n",
      "           6.3100e+00,  1.2550e+00,  5.6449e+00,  4.5203e+00,  1.4684e+01,\n",
      "           4.8294e+00,  8.7377e+00,  2.5576e+00,  7.0063e+00,  2.2820e+00,\n",
      "           4.2846e+00,  7.2354e-02,  8.1191e-01, -1.9826e+00,  3.5856e+00,\n",
      "          -8.8497e-01, -5.5653e-01, -2.2323e+00],\n",
      "         [ 9.0321e-01,  2.6344e+00,  1.3143e+00, -2.0931e+00, -3.1250e-01,\n",
      "          -1.4687e+00,  2.7223e+00,  3.6192e+00,  7.2542e+00,  7.7345e+00,\n",
      "           6.2970e+00,  2.1683e+00,  4.4432e+00,  7.1357e+00,  8.8503e+00,\n",
      "           7.9823e+00,  7.7220e+00,  2.4206e+00,  4.0365e+00,  3.1507e+00,\n",
      "           2.7710e+00,  7.7055e-01,  2.6992e-01, -2.8862e+00,  4.2839e-02,\n",
      "           9.4347e-01, -2.8605e+00, -7.6317e-01],\n",
      "         [ 2.5098e+00,  1.4310e+00,  1.7963e-01, -2.5758e+00,  9.4162e-01,\n",
      "          -2.4330e-01,  2.3616e+00,  2.1617e+00,  7.3967e+00,  5.0854e+00,\n",
      "           6.9040e+00,  1.8603e+00,  7.8607e+00,  6.0507e+00,  1.1635e+01,\n",
      "           4.4937e+00,  7.9154e+00,  4.9050e+00,  5.0214e+00,  1.5684e+00,\n",
      "           2.3326e+00, -4.1022e-01, -8.4720e-01, -3.9937e+00,  2.4673e+00,\n",
      "          -1.4094e+00, -4.3323e-02, -2.1389e+00],\n",
      "         [ 8.8764e-01,  2.1592e+00,  8.4801e-01, -2.5503e+00,  3.4999e-01,\n",
      "          -2.7903e+00,  1.9793e+00,  4.7810e+00,  1.1218e+01,  9.4754e+00,\n",
      "           9.9748e+00,  9.0148e+00,  1.0695e+01,  1.0616e+01,  8.9220e+00,\n",
      "           2.9235e+00,  8.0397e+00,  5.7853e+00,  5.5067e+00,  8.0944e-01,\n",
      "           5.7688e-01, -2.6459e+00, -2.7592e-01, -4.0596e+00,  7.1108e-01,\n",
      "          -7.0813e-02, -2.2266e+00, -1.0002e+00],\n",
      "         [ 1.1520e+00,  7.0649e-01, -6.4875e-01, -4.0723e+00, -1.7239e+00,\n",
      "          -4.9989e+00, -7.5478e-01,  1.2678e+00,  3.7478e+00,  4.2260e+00,\n",
      "           6.1321e+00,  6.3496e+00,  9.7625e+00,  6.7873e+00,  4.0777e+00,\n",
      "           1.4935e+00,  2.7838e+00, -1.5112e-01, -1.0547e+00, -3.5886e+00,\n",
      "          -2.1274e+00, -4.7624e+00, -2.3939e+00, -5.3591e+00,  1.5040e-01,\n",
      "          -1.6953e+00,  3.4162e-01, -2.1009e+00],\n",
      "         [ 1.5156e+00,  4.8565e+00,  2.5451e+00,  1.5478e+00, -3.3478e-01,\n",
      "          -1.1125e+00, -1.3011e+00, -1.1149e+00, -9.8809e-01,  1.8447e+00,\n",
      "          -7.0965e-02,  2.2952e+00,  1.7581e+00,  5.7161e-01, -5.5529e-02,\n",
      "           1.0493e+00, -6.9156e-02,  4.0053e-01, -8.2006e-01,  6.8046e-01,\n",
      "           2.0425e-02,  1.9232e-01,  3.4389e-01,  3.7400e-01,  1.5557e+00,\n",
      "           1.1671e+00, -4.9839e-01, -5.2139e-01],\n",
      "         [ 5.8214e+00,  3.8446e+00, -1.3811e+00, -2.1759e+00, -1.4632e+00,\n",
      "          -1.2849e+00, -3.2925e-01, -1.4027e+00, -8.8854e-01, -2.2751e+00,\n",
      "          -4.8324e-01, -2.6502e+00, -1.4065e+00, -2.5065e+00, -8.9797e-01,\n",
      "          -1.3365e+00, -1.2618e+00, -1.3029e+00, -7.4716e-01, -1.3211e+00,\n",
      "          -7.4013e-01, -2.0710e+00, -1.1705e+00, -1.6087e+00, -3.0826e-02,\n",
      "          -9.7705e-01, -2.5598e+00, -5.2194e+00],\n",
      "         [ 7.7410e+00,  7.5824e+00,  1.9034e+00,  3.3589e+00,  1.3291e+00,\n",
      "           2.9652e+00,  1.1922e+00,  2.5679e+00,  1.3586e+00,  3.0668e+00,\n",
      "           1.1245e+00,  2.4537e+00,  2.1702e+00,  1.4561e+00,  1.5192e+00,\n",
      "           1.8386e+00,  1.3121e+00,  1.9715e+00,  8.2695e-01,  2.9500e+00,\n",
      "           1.4457e+00,  2.8119e+00,  1.5766e+00,  2.3055e+00,  1.1275e+00,\n",
      "           1.1461e+00, -1.9755e-01, -3.8718e-01]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "digit = 9\n",
    "sample_batch_size = 10\n",
    "num_steps = 10\n",
    "sampler = em_sampler\n",
    "#score_model.eval()\n",
    "\n",
    "samples = sampler(score_model, marginal_prob_std,  diffusion_coeff, sample_batch_size, num_steps=num_steps,  y_tensor=digit*torch.ones(sample_batch_size, dtype=torch.long))\n",
    "\n",
    "#samples = samples.clamp(0.0, 1.0)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a grid of samples for visualization\n",
    "sample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\n",
    "\n",
    "# Plot the generated samples\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "plt.imshow(sample_grid.permute(1, 2, 0).cpu().to(int) )#, vmin=0., vmax=1.)\n",
    "plt.show()\n",
    "\n",
    "print(samples[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
